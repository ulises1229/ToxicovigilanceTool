{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToxicovigilanceTool.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYBH6jGpomcTyRjHxlPMoy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulises1229/ToxicovigilanceTool/blob/main/code/ToxicovigilanceTool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toxicovigilance tool\n",
        "+ Author: Ulises Olivares\n",
        "+ Email: uolivares@unam.mx\n",
        "+ Dec 21, 2021"
      ],
      "metadata": {
        "id": "e_X9BWYCCqOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import dataframe"
      ],
      "metadata": {
        "id": "7lGgJRBfCvI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Split data "
      ],
      "metadata": {
        "id": "MJ0J4B99Cuqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import datasets"
      ],
      "metadata": {
        "id": "IUUdwo9NoQg3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT7PmyG9Coyb"
      },
      "outputs": [],
      "source": [
        "prado = pd.read_csv(\"https://raw.githubusercontent.com/HpcDataLab/ToxicovigilanceTool/main/data/Daily_flight_activity_Prado.csv\")\n",
        "prado.head(100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Descibe dataset"
      ],
      "metadata": {
        "id": "lebB-SQ-tXwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prado.describe()"
      ],
      "metadata": {
        "id": "cT_dRBIgtU5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique bees: \", len(prado.ID.unique()))\n",
        "\n",
        "# Subdivide data 70% training 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(prado, prado.Treatment, test_size=0.3)\n",
        "\n",
        "print(\"Number of registers:\", prado.shape)\n",
        "\n",
        "# Training data\n",
        "print(\"Shape of data for training:\",X_train.shape)\n",
        "\n",
        "# Testing data\n",
        "print(\"Shape of data for testing:\",X_test.shape)\n",
        "\n",
        "#print(\"Training data\", X_train)\n",
        "\n",
        "print(\"Unique bees: \", len(X_train.ID.unique()))"
      ],
      "metadata": {
        "id": "ABQ7J-lRDy4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Subdivide registers into two subsets: Control and pesticides"
      ],
      "metadata": {
        "id": "kJA47A885ZwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separete a single bee \n",
        "single = prado[prado.ID ==  \"K 4152\"] \n",
        "\n",
        "# Separate control bees\n",
        "control = prado[prado.Treatment == \"control\"]\n",
        "\n",
        "# Separate pesticide bees\n",
        "pesticide = prado[prado.Treatment == \"pesticide\"]\n",
        "\n",
        "print(\"Number of control registers: \", len(control))\n",
        "print(\"Unique control bees\",len(control.ID.unique()))\n",
        "\n",
        "print(\"Number of pesticide registers: \", len(pesticide))\n",
        "print(\"Unique pesticide bees\",len(pesticide.ID.unique()))\n",
        "\n",
        "print(\"Total registers for K 4150:\",len(single))\n",
        "\n",
        "# Subdivide data 70% training 30% test Control\n",
        "C_X_train, C_X_test, C_y_train, C_y_test = train_test_split(control, control.Treatment, test_size=0.3)\n",
        "\n",
        "P_X_train, P_X_test, P_y_train, P_y_test = train_test_split(pesticide, pesticide.Treatment, test_size=0.3)\n",
        "\n",
        "print(\"Total training control registers: \",len(C_X_train))\n",
        "print(\"Total training pesticide registers: \", len(P_X_train))\n",
        "\n",
        "# merge testing and training datasets\n",
        "X_train = pd.merge(C_X_train, P_X_train, how=\"outer\")\n",
        "X_test =  pd.merge(C_X_test, P_X_test, how=\"outer\")\n",
        "\n",
        "y_train = pd.merge(C_y_train, P_y_train, how=\"outer\")\n",
        "y_test =  pd.merge(C_y_test, P_y_test, how=\"outer\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Total train Regs.\", len(X_train))\n",
        "print(\"Total test Regs.\", len(X_test))\n",
        "\n",
        "#print(X_train)\n"
      ],
      "metadata": {
        "id": "CWDG4Ftb08cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(trainSize):\n",
        "    model = keras.Sequential()\n",
        "    # Add an Embedding layer expecting input vocab of size 1000, and\n",
        "    # output embedding dimension of size 64.\n",
        "    model.add(layers.Embedding(input_dim=trainSize, output_dim=1024))\n",
        "\n",
        "    # Add a LSTM layer with 128 internal units.\n",
        "    model.add(layers.LSTM(1024))\n",
        "\n",
        "    # Add a Dense layer with 2 units.\n",
        "    model.add(layers.Dense(2))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build a simple model with default hyperparameters. You will get the \n",
        "#   chance to change these later.\n",
        "model = build_model(len(X_train))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JMrX3_GhAQ49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EL6eJoPn5Wum"
      }
    }
  ]
}